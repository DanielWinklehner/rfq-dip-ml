{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UQ Analysis of RFQ Dataset (09-24-2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <div class=\"alert alert-info\" style=\"background-color:rgba(255, 0, 0, 0.6);\n",
    "                                         margin-top:10px;\n",
    "                                         color:white;\n",
    "                                         border-color:rgba(255, 0, 0, 0.3);\n",
    "                                         font-size: 15px\">\n",
    "        <strong>Requirements:</strong>\n",
    "        <ul>\n",
    "            <li>pyOPALTools (https://gitlab.psi.ch/OPAL/pyOPALTools/-/tags/pyOPALTools-25-09-2020)</li>\n",
    "            <li>UQTk (https://github.com/sandialabs/UQTk)</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</html>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <div class=\"alert alert-info\" role=\"alert\" style=\"margin-top: 10px; font-size: 30px;\">\n",
    "        <strong>Define Global Variables</strong>\n",
    "    </div>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renamed file: 'Dataset_RFQ-model_01_(09-24-2020).txt' --> 'dataset_0.json'\n",
    "fname = 'dataset_0.json'\n",
    "\n",
    "# polynomial chaos expansion order\n",
    "order = 2\n",
    "iteration = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPAL ML Database Generator \u001b[6;30;42m\u001b[0m\n",
      "Write ML-Database sampler.pk\n"
     ]
    }
   ],
   "source": [
    "from db import mldb\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#from mllib.model import *\n",
    "#from mllib.data import OpalDataSource\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "database = mldb.mldb()\n",
    "\n",
    "database.buildFromSampler(fname, '.', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xDim        = 23 -> ['DVAR1', 'DVAR2', 'DVAR3', 'DVAR4', 'DVAR5', 'DVAR6', 'DVAR7', 'DVAR8', 'DVAR9', 'DVAR10', 'DVAR11', 'DVAR12', 'DVAR13', 'DVAR14', 'DVAR15', 'DVAR16', 'DVAR17', 'DVAR18', 'DVAR19', 'DVAR20', 'DVAR21', 'DVAR22', 'DVAR23']\n",
      "yDim        = 7 -> ['OBJ1', 'OBJ2', 'OBJ3', 'OBJ4', 'OBJ5', 'OBJ6', 'OBJ7']\n",
      "generations = 1\n",
      "Data points  = 189914\n",
      "Show first dataset from generation 0: y = f(x)\n",
      "[3.860e+01 7.813e+01 5.900e-02 3.200e+01 6.767e-02 5.917e-02 6.448e-02] = f([ 3.71075400e+00  1.09702490e+01 -4.82822200e+01 -3.22640300e+00\n",
      "  5.98268900e+00  1.87969530e+01  3.92952568e+02  1.15695680e+01\n",
      "  1.33398551e+02  1.57871634e+02  1.69266700e+00  1.83418200e+00\n",
      "  3.77366858e+02  4.71364189e+02  3.15951420e+01  4.30351050e+01\n",
      " -5.34608370e+01 -3.23305160e+01  3.49221138e+02  4.98208768e+02\n",
      "  1.95883600e+00 -2.44117280e+01  5.63830000e-02])\n"
     ]
    }
   ],
   "source": [
    "database.printOverview ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <div class=\"alert alert-info\" role=\"alert\" style=\"margin-top: 10px; font-size: 30px;\">\n",
    "        <strong>Save Input and Output</strong>\n",
    "    </div>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Note: The ordering of the intput and output data are ordered according to 'xnames' and 'ynames' which does not\n",
    "necessarily mean an increasing ordering, i.e., DVAR1, DVAR2, ... or OBJ1, OBJ\", ..., respectively.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "xnames = database.getXNames()\n",
    "ynames = database.getYNames()\n",
    "xdim = database.getXDim()\n",
    "ydim = database.getYDim()\n",
    "nsamples = database.getSampleSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvals = np.zeros((nsamples, xdim))\n",
    "yvals = np.zeros((nsamples, ydim))\n",
    "for i in range(nsamples):\n",
    "    xvals[i] = database.getDVarVec(0, i)\n",
    "    yvals[i] = database.getObjVec(0, i)\n",
    "\n",
    "# save data, might be used for Neural Network training\n",
    "np.save('rfq_input.npy', xvals)\n",
    "np.save('rfq_output.npy',yvals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <div class=\"alert alert-info\" role=\"alert\" style=\"margin-top: 10px; font-size: 30px;\">\n",
    "        <strong>Obtain Domain of Interest from Data</strong>\n",
    "    </div>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pdom = np.empty((2, len(xnames)))\n",
    "\n",
    "bounds = database.getBounds()\n",
    "\n",
    "for i in range(len(xnames)):\n",
    "    pdom[0, i] = bounds[xnames[i]][0]\n",
    "    pdom[1, i] = bounds[xnames[i]][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <div class=\"alert alert-info\" role=\"alert\" style=\"margin-top: 10px; font-size: 30px;\">\n",
    "        <strong>Split into Training and Validation Data</strong>\n",
    "    </div>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size:    132939\n",
      "Validation size:  56975\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(xvals, yvals, test_size=0.3, random_state=42)\n",
    "\n",
    "print('Training size:   ', np.shape(xtrain)[0])\n",
    "print('Validation size: ', np.shape(ytest)[0])\n",
    "#ytrain = keras.utils.to_categorical(ytrain)\n",
    "\n",
    "#ytest = keras.utils.to_categorical(ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<html>\n",
    "    <div class=\"alert alert-info\" role=\"alert\" style=\"margin-top: 10px; font-size: 30px;\">\n",
    "        <strong>Analysis Functions</strong>\n",
    "    </div>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Error Measures and Sensitivity Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error measures\n",
    "def eval_l2_error(ytrue, ypred):\n",
    "    return np.linalg.norm(ytrue - ypred, ord=2) / np.linalg.norm(ytrue, ord=2)\n",
    "\n",
    "def eval_l1_error(ytrue, ypred):\n",
    "    return np.linalg.norm(ytrue - ypred, ord=1) / np.linalg.norm(ytrue, ord=1)\n",
    "\n",
    "def compute_sensitivity(xtrain, ytrain, order, pdom):\n",
    "    import numpy as np\n",
    "    allsens_m = np.zeros((len(ytrain[0]), len(xtrain[0])))\n",
    "    allsens_t = np.zeros((len(ytrain[0]), len(xtrain[0])))\n",
    "    \n",
    "    # load the UQ interface\n",
    "    from surrogate.uqtk_model import UQTk as UQ\n",
    "    #from surrogate.chaospy_model import UQChaospy as UQ\n",
    "    \n",
    "    \n",
    "    for i in range(len(ytrain[0])):\n",
    "        # delete\n",
    "        uq = None\n",
    "\n",
    "        # setup the UQ analysis ( lsq : least squares method )\n",
    "        uq = UQ(pdom=pdom, order=order, method='lsq')\n",
    "    \n",
    "        # train the surrogate model\n",
    "        uq.fit(xtrain, ytrain[:, i])\n",
    "        \n",
    "        allsens_m[i, :] = uq.main_sensitivity()\n",
    "        allsens_t[i, :] = uq.total_sensitivity()\n",
    "    \n",
    "    return allsens_m, allsens_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Sensitivity Plotting Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sens(sensdata,pars,cases,vis=\"bar\",\n",
    "              par_labels=[], case_labels=[],colors=[],ncol=4,grid_show=True,xlbl='',\n",
    "              legend_show=2,xdatatick=None,figname='sens.eps',showplot=False, **kwargs):\n",
    "\n",
    "    \"\"\"Plots sensitivity for multiple observables\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    ncases=sensdata.shape[0]\n",
    "    npar=sensdata.shape[1]\n",
    "    \n",
    "    sens_type = kwargs.pop('sens_type', '')\n",
    "\n",
    "    wd=0.6\n",
    "    ylbl= sens_type + ' Sensitivity'\n",
    "\n",
    "\n",
    "    assert set(pars) <= set(range(npar))\n",
    "    assert set(cases) <= set(range(ncases))\n",
    "\n",
    "    npar_=len(pars)\n",
    "    ncases_=len(cases)\n",
    "\n",
    "    case_labels_=[]\n",
    "    for i in range(ncases_):\n",
    "        case_labels_.append(case_labels[cases[i]])\n",
    "\n",
    "    if xdatatick==None:\n",
    "        xflag=False\n",
    "        xdatatick=np.array(list(range(1,ncases_+1)))\n",
    "        sc=1.\n",
    "    else:\n",
    "        xflag=True\n",
    "        sc=(xdatatick[-1]-xdatatick[0])/ncases_\n",
    "\n",
    "    if (vis==\"graph\"):\n",
    "        for i in range(npar_):\n",
    "            plt.plot(xdatatick_,sensdata[cases,i], '-o',color=colors[pars[i]], label=par_labels[pars[i]])\n",
    "    elif (vis==\"bar\"):\n",
    "        curr=np.zeros((ncases_))\n",
    "        #print pars,colors\n",
    "        for i in range(npar_):\n",
    "            plt.bar(xdatatick,sensdata[cases,i], width=wd*sc,color=colors[pars[i]], bottom=curr,\n",
    "                    label=par_labels[pars[i]], capsize=5, ecolor='black')\n",
    "            curr=sensdata[cases,i]+curr\n",
    "        if not xflag:\n",
    "            plt.xticks(np.array(list(range(1,ncases_+1))),case_labels_)\n",
    "        plt.xlim(xdatatick[0]-wd*sc/2.,xdatatick[-1]+wd*sc/2.)\n",
    "\n",
    "    plt.ylabel(ylbl)\n",
    "    plt.xlabel(xlbl)\n",
    "\n",
    "    maxsens=max(max(curr),1.0)\n",
    "    plt.ylim([0,maxsens])\n",
    "    if legend_show==1:\n",
    "        plt.legend()\n",
    "    elif (legend_show==2):\n",
    "        plt.legend(loc = 'upper center', bbox_to_anchor=(0.5, 1.1), ncol=ncol)\n",
    "    elif legend_show == 3:\n",
    "        bb_shift = kwargs.pop('bb_shift', 0.0)\n",
    "        plt.legend(loc = 'upper left', bbox_to_anchor=(-0.75+bb_shift, 1.25), ncol=ncol)\n",
    "        #legend(bbox_to_anchor=(0.0, -0.05),fancybox=True, shadow=True,ncol=5,labelspacing=-0.1)\n",
    "\n",
    "    #if not xflag:\n",
    "    #    zed = [tick.label.set_fontsize(xticklabel_size) for tick in plt.gca().xaxis.get_major_ticks()]\n",
    "\n",
    "    plt.grid(grid_show, linestyle='dashed', axis='y')\n",
    "    #plt.tight_layout()\n",
    "    return plt\n",
    "\n",
    "def plot_sensitivity(sensdata, dnames, outnames, **kwargs):\n",
    "    import matplotlib.pyplot as plt\n",
    "    ## Get basic dimensions\n",
    "    nout=len(outnames)\n",
    "    ndim=np.shape(sensdata)[1]\n",
    "    print(\"Dimensionality : \", ndim)\n",
    "    print(\"Num of outputs : \", nout)\n",
    "\n",
    "    pars=list(range(ndim))\n",
    "    cases=list(range(nout))\n",
    "\n",
    "    # 11. March 2019\n",
    "    # https://stackoverflow.com/questions/43938425/matplotlib-change-colormap-tab20-to-have-three-colors\n",
    "    colors = plt.cm.tab20( (4./3*np.arange(20*3/4)).astype(int) )\n",
    "\n",
    "    return plot_sens(sensdata, pars, cases, vis='bar', colors=colors,\n",
    "                     par_labels=dnames,case_labels=outnames,ncol=int(0.5*ndim),\n",
    "                     grid_show=True, xlbl='', **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <div class=\"alert alert-info\" role=\"alert\" style=\"margin-top: 10px; font-size: 30px;\">\n",
    "        <strong>Train UQ Model and Check the Error</strong>\n",
    "    </div>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"Demonstrate Keras model weight shuffling as fast alternative to re-creating a model.\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "def shuffle_weights(model, weights=None):\n",
    "    \"\"\"Randomly permute the weights in `model`, or the given `weights`.\n",
    "    This is a fast approximation of re-initializing the weights of a model.\n",
    "    Assumes weights are distributed independently of the dimensions of the weight tensors\n",
    "      (i.e., the weights have the same distribution along each dimension).\n",
    "    :param Model model: Modify the weights of the given model.\n",
    "    :param list(ndarray) weights: The model's weights will be replaced by a random permutation of these weights.\n",
    "      If `None`, permute the model's current weights.\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = model.get_weights()\n",
    "    weights = [np.random.permutation(w.flat).reshape(w.shape) for w in weights]\n",
    "    # Faster, but less random: only permutes along the first dimension\n",
    "    # weights = [np.random.permutation(w) for w in weights]\n",
    "    model.set_weights(weights)\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     \"\"\"Train a simple single layer to learn the sum of three inputs.\n",
    "#     Shuffle weights in a mock \"cross-validation\" loop instead of re-creating the model to save time.\n",
    "#     \"\"\"\n",
    "#     np.random.seed(42)\n",
    "#     model = Sequential((\n",
    "#         Dense(input_dim=3, output_dim=1, activation='linear'),\n",
    "#     ))\n",
    "#     model.compile(loss='msle', optimizer='rmsprop')\n",
    "\n",
    "#     X = np.random.random(size=(1000, 3))\n",
    "#     y = np.sum(X, axis=1)\n",
    "\n",
    "#     initial_weights = model.get_weights()\n",
    "#     print('Initial weights:\\n', initial_weights)\n",
    "\n",
    "#     for rnd in xrange(3):\n",
    "#         shuffle_weights(model, initial_weights)\n",
    "#         print('\\nRound {} starting weights:\\n'.format(rnd), model.get_weights())\n",
    "#         hist = model.fit(X, y, nb_epoch=50, verbose=0)\n",
    "#         print('Learned weights:\\n', model.get_weights(), '\\nloss:', hist.history['loss'][-1])\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Antirectifier(layers.Layer):\n",
    "    def __init__(self, initializer=\"he_normal\", **kwargs):\n",
    "        super(Antirectifier, self).__init__(**kwargs)\n",
    "        self.initializer = keras.initializers.get(initializer)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        output_dim = input_shape[-1]\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(output_dim * 2, output_dim),\n",
    "            initializer=self.initializer,\n",
    "            name=\"kernel\",\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs -= tf.reduce_mean(inputs, axis=-1, keepdims=True)\n",
    "        pos = tf.nn.relu(inputs)\n",
    "        neg = tf.nn.relu(-inputs)\n",
    "        concatenated = tf.concat([pos, neg], axis=-1)\n",
    "        mixed = tf.matmul(concatenated, self.kernel)\n",
    "        return mixed\n",
    "\n",
    "    def get_config(self):\n",
    "        # Implement get_config to enable serialization. This is optional.\n",
    "        base_config = super(Antirectifier, self).get_config()\n",
    "        config = {\"initializer\": keras.initializers.serialize(self.initializer)}\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 14)                42        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                150       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 14)                294       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 1,141\n",
      "Trainable params: 1,141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "132939\n",
      "7\n",
      "0.09658000000000001\n",
      "Epoch 1/10000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/loyd/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /home/loyd/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/loyd/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/loyd/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/loyd/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/loyd/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /home/loyd/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:747 train_step\n        y_pred = self(x, training=True)\n    /home/loyd/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    /home/loyd/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:212 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_1 is incompatible with the layer: expected axis -1 of input shape to have value 2 but received input with shape [None, 23]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-93f20aa38271>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;31m#trainer=normalize(ytrain[:,obj])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mnorms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormfactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnormfactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;31m# Test the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;31m#model.evaluate(xtest, ytest[:,obj])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 696\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    697\u001b[0m             *args, **kwds))\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3065\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/loyd/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /home/loyd/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/loyd/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/loyd/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/loyd/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/loyd/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /home/loyd/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:747 train_step\n        y_pred = self(x, training=True)\n    /home/loyd/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    /home/loyd/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:212 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_1 is incompatible with the layer: expected axis -1 of input shape to have value 2 but received input with shape [None, 23]\n"
     ]
    }
   ],
   "source": [
    "# load the UQ interface\n",
    "#from surrogate.uqtk_model import UQTk as UQ\n",
    "#from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "#xtrain = xtrain.reshape(-1,14)\n",
    "#ytrain=ytrain.reshape(-1,6)\n",
    "models=[]\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 500\n",
    "\n",
    "epochs = 10000\n",
    "\n",
    "def normalize(v):\n",
    "    norm = np.linalg.norm(v)\n",
    "    if norm == 0: \n",
    "        return v\n",
    "    else: \n",
    "        return v / norm\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(14, input_dim=2, activation='sigmoid'))\n",
    "#model.add(Dropout(0.5))\n",
    "#add in sigmoids/tanh\n",
    "#check bias terms\n",
    "#go big immediately\n",
    "#plot loss\n",
    "\n",
    "#model.add(Dense(24, activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "#model.add(Dense(48, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "#model.add(Dense(100, activation='tanh'))\n",
    "#model.add(Dropout(0.8))\n",
    "\n",
    "\n",
    "# model.add(Dense(80, activation='sigmoid'))\n",
    "\n",
    "# model.add(Dense(50, activation='tanh'))\n",
    "\n",
    "# model.add(Dense(50, activation='tanh'))\n",
    "\n",
    "# model.add(Dense(20, activation='tanh'))\n",
    "# model.add(Dense(20, activation='tanh'))\n",
    "# model.add(Dense(20, activation='tanh'))\n",
    "# model.add(Dense(20, activation='tanh'))\n",
    "# model.add(Dense(20, activation='tanh'))\n",
    "# model.add(Dense(20, activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(10, activation='tanh'))\n",
    "model.add(Dense(20, activation='tanh'))\n",
    "model.add(Dense(20, activation='tanh'))\n",
    "model.add(Dense(14, activation='tanh'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model.add(Dense(100, activation='tanh'))\n",
    "\n",
    "# model.add(Dense(100, activation='tanh'))\n",
    "\n",
    "# model.add(Dense(48, activation='sigmoid'))\n",
    "# #model.add(Dropout(0.8))\n",
    "\n",
    "# model.add(Dense(24, activation='sigmoid'))\n",
    "# #model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Dense(20, activation='sigmoid'))\n",
    "#model.add(Dropout(0.5))\n",
    "# never reduces smaller than input\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#model.add(Dense(6))\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "obj=2\n",
    "models=[]\n",
    "norms=[]\n",
    "\n",
    "print(len(ytrain[:,obj]))\n",
    "print(len(ytrain[obj,:]))\n",
    "while obj<3:\n",
    "    \n",
    "    \n",
    "    # Compile the model\n",
    "model.compile(\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    #use loss squared function\n",
    "    #optimizer=keras.optimizers.Adam(learning_rate=.0136),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=.001),\n",
    "    #switch to adam\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "    \n",
    "    normfactor=np.max(ytrain[:,obj])*1.1\n",
    "    print(normfactor)\n",
    "    #normfactor=normalize(ytrain[:,obj])\n",
    "    #trainer=normalize(ytrain[:,obj])\n",
    "    norms.append(normfactor)\n",
    "    model.fit(xtrain, ytrain[:,obj]/normfactor, batch_size=batch_size, epochs=epochs, validation_split=0.0)\n",
    "    # Test the model\n",
    "    #model.evaluate(xtest, ytest[:,obj])\n",
    "    models.append(model)\n",
    "    obj=obj+1\n",
    "    #shuffle_weights(model, weights=None)\n",
    "    \n",
    "obj=1\n",
    "\n",
    "\n",
    "#print(xtrain[1,:])\n",
    "#print(ytrain[9,:])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.044000000000000004]\n",
      "-------------\n",
      "predictions:  [[0.03210482]\n",
      " [0.03610436]\n",
      " [0.03666614]\n",
      " [0.03208328]\n",
      " [0.03158597]\n",
      " [0.03169082]\n",
      " [0.0321293 ]\n",
      " [0.04048665]\n",
      " [0.03227307]\n",
      " [0.03000356]\n",
      " [0.04021327]\n",
      " [0.03384917]\n",
      " [0.03775004]\n",
      " [0.03220446]\n",
      " [0.03462695]\n",
      " [0.03868614]\n",
      " [0.03174311]\n",
      " [0.04000011]\n",
      " [0.03206446]\n",
      " [0.02986591]\n",
      " [0.03007286]\n",
      " [0.0301525 ]\n",
      " [0.02900578]\n",
      " [0.0297471 ]\n",
      " [0.02960629]\n",
      " [0.03205606]\n",
      " [0.04021931]\n",
      " [0.03208014]\n",
      " [0.03009423]\n",
      " [0.03836489]]\n",
      "%%%%%%%%%%%%%%%%%%\n",
      "MAE:  0.0035877137\n",
      "normalized MAE:  0.10641523680286641\n"
     ]
    }
   ],
   "source": [
    "#print(ytest[90,:])\n",
    "print(norms)\n",
    "#models[0].predict(xtest)[90]*norms[0]\n",
    "\n",
    "print(\"-------------\")\n",
    "#print(pow(np.average(models[0].predict(xtest)*norms[0]-ytest[:,2]),2))\n",
    "#print(\"ytest: \", ytest[:,5])\n",
    "print(\"predictions: \", abs(models[0].predict(xtest)*norms[0]))\n",
    "      \n",
    "predictions =[]\n",
    "predictions=models[0].predict(xtest)*norms[0]\n",
    "\n",
    "\n",
    "#1087.4565184720586\n",
    "\n",
    "# print(\"***************\")\n",
    "# print(\"MAE: \", np.average(abs(predictions-ytest[:,2])))\n",
    "# print(\"normalized MAE: \", np.average(abs(models[0].predict(xtest)*norms[0]-ytest[:,2]))/np.average(ytrain[:,2]))\n",
    "\n",
    "difs=[]\n",
    "q=0\n",
    "while q<len(predictions)-1:\n",
    "   difs.append(abs(predictions[q]-ytest[q,2]))\n",
    "   q=q+1\n",
    "    \n",
    "print(\"%%%%%%%%%%%%%%%%%%\")\n",
    "print(\"MAE: \", np.average(difs))\n",
    "print(\"normalized MAE: \", np.average(difs)/np.average(ytrain[:,2]))\n",
    "    \n",
    "\n",
    "# print(\"&&&&&&&&&&&&&&&&&&&&&&&&&\")\n",
    "# print(\"prediction:\",( models[0].predict(xtest)[90]*norms[0]) )\n",
    "# print(\"ytest:\",ytest[90,2])\n",
    "\n",
    "\n",
    "# print(\"^^^^^^^^^^^^^^^^\")\n",
    "# q=0\n",
    "# while q<len(predictions)-1:\n",
    "#     #print(q)\n",
    "#     if (abs(predictions[q]-ytest[q,2])) > 10:\n",
    "#         print(\"q: \" , q, \"   prediction: \", predictions[q], \"       ytest: \", ytest[q,2], \"   dif: \", abs(predictions[q]-ytest[q,2]) )\n",
    "#     q=q+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "obj = 0\n",
    "#print(xtrain)\n",
    "\n",
    "\n",
    "while obj<1:\n",
    "    predictions=[]\n",
    "    #predictions=models[obj].predict(xtest)*norms[obj]\n",
    "    #predictions=models[obj].predict(xtest)*norms[obj]\n",
    "    predictions=model.predict(xtest)*normfactor\n",
    "    \n",
    "    print(len(models))\n",
    "    #print(len(predictions[:,obj]))\n",
    "    #print(len(ytest))\n",
    "    fig = plt.figure()\n",
    "    ax2 = fig.add_subplot(111)\n",
    "    \n",
    "\n",
    "    ax2.scatter(ytest[:,obj], ytest[:,obj],\n",
    "             \n",
    "             label='y=x',\n",
    "            s=1, c='b', marker=\"s\",\n",
    "             )\n",
    "    ax2.scatter(ytest[:,obj], predictions,\n",
    "             s=.01, c='r', marker=\"o\",\n",
    "             label='Prediction')\n",
    "    ax2.set_aspect(1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if obj==0:\n",
    "        ax2.set_xlabel('transmission(%)')\n",
    "        ax2.set_ylabel('transmission(%)')\n",
    "    \n",
    "    if obj==1:\n",
    "        ax2.set_xlabel('Energy(MeV)')\n",
    "        ax2.set_ylabel('Energy(MeV)')\n",
    "        \n",
    "    if obj==2:\n",
    "        ax2.set_xlabel('length(mm)')\n",
    "        ax2.set_ylabel('length(mm)')\n",
    "        \n",
    "    \n",
    "    if obj==3:\n",
    "        ax2.set_xlabel('Longitudinal emit (mm*mrad)')\n",
    "        ax2.set_ylabel('Longitudinal emit (mm*mrad)')\n",
    "        \n",
    "        \n",
    "    \n",
    "    if obj==4:\n",
    "        ax2.set_xlabel('X emit (mm*mrad)')\n",
    "        ax2.set_ylabel('X emit (mm*mrad)')\n",
    "                \n",
    "    if obj==5:\n",
    "        ax2.set_xlabel('Y emit (mm*mrad)')\n",
    "        ax2.set_ylabel('Y emit (mm*mrad)')\n",
    "        \n",
    "\n",
    "    #ax2.set_xlim(0.055, .1)\n",
    "    #ax2.set_ylim(0, .1)\n",
    "    #ax2.set_xlim(0, .1)\n",
    "    plt.legend(loc='upper left');\n",
    "    \n",
    "\n",
    "#plt.plot(xvals[:,1], yvals[:,1], label='')\n",
    "    plt.show()\n",
    "    obj = obj +1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <div class=\"alert alert-info\" role=\"alert\" style=\"margin-top: 10px; font-size: 30px;\">\n",
    "        <strong>Generate Database</strong>\n",
    "    </div>\n",
    "\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "No loop matching the specified signature and casting was found for ufunc add",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-2b88295cc3cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mnbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian_kde\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m  \u001b[0mytest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m  \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mxi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgrid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnbins\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1j\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnbins\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1j\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mzi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, bw_method, weights)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_neff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weights\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_bandwidth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbw_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbw_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36mset_bandwidth\u001b[0;34m(self, bw_method)\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_covariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compute_covariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36m_compute_covariance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;31m# Cache covariance and inverse covariance of the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_data_inv_cov'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m             self._data_covariance = atleast_2d(cov(self.dataset, rowvar=1,\n\u001b[0m\u001b[1;32m    575\u001b[0m                                                \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m                                                aweights=self.weights))\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mcov\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.8/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mcov\u001b[0;34m(m, y, rowvar, bias, ddof, fweights, aweights)\u001b[0m\n\u001b[1;32m   2454\u001b[0m             \u001b[0mw\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0maweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2456\u001b[0;31m     \u001b[0mavg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2457\u001b[0m     \u001b[0mw_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_sum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36maverage\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.8/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36maverage\u001b[0;34m(a, axis, weights, returned)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mwgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mscl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscl\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             raise ZeroDivisionError(\n",
      "\u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.8/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     45\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     46\u001b[0m          initial=_NoValue, where=True):\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[0;31mTypeError\u001b[0m: No loop matching the specified signature and casting was found for ufunc add"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAANQklEQVR4nO3cX4il9X3H8fenuxEak0aJk5DurmRb1pi90KITI6VpTUObXXuxBLxQQ6QSWKQx5FIpNLnwprkohKBmWWSR3GQvGkk2ZRMplMSCNd1Z8N8qynSlOl3BNYYUDFRWv704p51hnHWenXNmZp3v+wUD85znNzPf+TH73mfPznlSVUiStr7f2ewBJEkbw+BLUhMGX5KaMPiS1ITBl6QmDL4kNbFq8JMcSfJakmfPcz5JvptkPsnTSa6b/piSpEkNucJ/GNj3Huf3A3vGbweB700+liRp2lYNflU9BrzxHksOAN+vkSeAy5J8YloDSpKmY/sUPscO4JUlxwvjx15dvjDJQUb/CuDSSy+9/uqrr57Cl5ekPk6ePPl6Vc2s5WOnEfys8NiK92uoqsPAYYDZ2dmam5ubwpeXpD6S/OdaP3Yav6WzAOxacrwTODOFzytJmqJpBP8YcMf4t3VuBH5TVe96OkeStLlWfUonyQ+Am4ArkiwA3wI+AFBVh4DjwM3APPBb4M71GlaStHarBr+qblvlfAFfm9pEkqR14SttJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJamJQ8JPsS/JCkvkk965w/iNJfpLkqSSnktw5/VElSZNYNfhJtgEPAPuBvcBtSfYuW/Y14Lmquha4CfiHJJdMeVZJ0gSGXOHfAMxX1emqegs4ChxYtqaADycJ8CHgDeDcVCeVJE1kSPB3AK8sOV4YP7bU/cCngTPAM8A3quqd5Z8oycEkc0nmzp49u8aRJUlrMST4WeGxWnb8ReBJ4PeBPwLuT/J77/qgqsNVNVtVszMzMxc4qiRpEkOCvwDsWnK8k9GV/FJ3Ao/UyDzwEnD1dEaUJE3DkOCfAPYk2T3+j9hbgWPL1rwMfAEgyceBTwGnpzmoJGky21dbUFXnktwNPApsA45U1akkd43PHwLuAx5O8gyjp4DuqarX13FuSdIFWjX4AFV1HDi+7LFDS94/A/zldEeTJE2Tr7SVpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDUxKPhJ9iV5Icl8knvPs+amJE8mOZXkF9MdU5I0qe2rLUiyDXgA+AtgATiR5FhVPbdkzWXAg8C+qno5ycfWaV5J0hoNucK/AZivqtNV9RZwFDiwbM3twCNV9TJAVb023TElSZMaEvwdwCtLjhfGjy11FXB5kp8nOZnkjpU+UZKDSeaSzJ09e3ZtE0uS1mRI8LPCY7XseDtwPfBXwBeBv0ty1bs+qOpwVc1W1ezMzMwFDytJWrtVn8NndEW/a8nxTuDMCmter6o3gTeTPAZcC7w4lSklSRMbcoV/AtiTZHeSS4BbgWPL1vwY+FyS7Uk+CHwWeH66o0qSJrHqFX5VnUtyN/AosA04UlWnktw1Pn+oqp5P8jPgaeAd4KGqenY9B5ckXZhULX86fmPMzs7W3NzcpnxtSXq/SnKyqmbX8rG+0laSmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmBgU/yb4kLySZT3Lve6z7TJK3k9wyvRElSdOwavCTbAMeAPYDe4Hbkuw9z7pvA49Oe0hJ0uSGXOHfAMxX1emqegs4ChxYYd3XgR8Cr01xPknSlAwJ/g7glSXHC+PH/l+SHcCXgEPv9YmSHEwyl2Tu7NmzFzqrJGkCQ4KfFR6rZcffAe6pqrff6xNV1eGqmq2q2ZmZmYEjSpKmYfuANQvAriXHO4Ezy9bMAkeTAFwB3JzkXFX9aBpDSpImNyT4J4A9SXYD/wXcCty+dEFV7f6/95M8DPyTsZeki8uqwa+qc0nuZvTbN9uAI1V1Ksld4/Pv+by9JOniMOQKn6o6Dhxf9tiKoa+qv558LEnStPlKW0lqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSE4OCn2RfkheSzCe5d4XzX07y9Pjt8STXTn9USdIkVg1+km3AA8B+YC9wW5K9y5a9BPxZVV0D3AccnvagkqTJDLnCvwGYr6rTVfUWcBQ4sHRBVT1eVb8eHz4B7JzumJKkSQ0J/g7glSXHC+PHzuerwE9XOpHkYJK5JHNnz54dPqUkaWJDgp8VHqsVFyafZxT8e1Y6X1WHq2q2qmZnZmaGTylJmtj2AWsWgF1LjncCZ5YvSnIN8BCwv6p+NZ3xJEnTMuQK/wSwJ8nuJJcAtwLHli5IciXwCPCVqnpx+mNKkia16hV+VZ1LcjfwKLANOFJVp5LcNT5/CPgm8FHgwSQA56pqdv3GliRdqFSt+HT8upudna25ublN+dqS9H6V5ORaL6h9pa0kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNDAp+kn1JXkgyn+TeFc4nyXfH559Oct30R5UkTWLV4CfZBjwA7Af2Arcl2bts2X5gz/jtIPC9Kc8pSZrQkCv8G4D5qjpdVW8BR4EDy9YcAL5fI08AlyX5xJRnlSRNYPuANTuAV5YcLwCfHbBmB/Dq0kVJDjL6FwDA/yR59oKm3bquAF7f7CEuEu7FIvdikXux6FNr/cAhwc8Kj9Ua1lBVh4HDAEnmqmp2wNff8tyLRe7FIvdikXuxKMncWj92yFM6C8CuJcc7gTNrWCNJ2kRDgn8C2JNkd5JLgFuBY8vWHAPuGP+2zo3Ab6rq1eWfSJK0eVZ9SqeqziW5G3gU2AYcqapTSe4anz8EHAduBuaB3wJ3Dvjah9c89dbjXixyLxa5F4vci0Vr3otUveupdknSFuQrbSWpCYMvSU2se/C9LcOiAXvx5fEePJ3k8STXbsacG2G1vViy7jNJ3k5yy0bOt5GG7EWSm5I8meRUkl9s9IwbZcCfkY8k+UmSp8Z7MeT/C993khxJ8tr5Xqu05m5W1bq9MfpP3v8A/gC4BHgK2Ltszc3ATxn9Lv+NwC/Xc6bNehu4F38MXD5+f3/nvViy7l8Y/VLALZs99yb+XFwGPAdcOT7+2GbPvYl78bfAt8fvzwBvAJds9uzrsBd/ClwHPHue82vq5npf4XtbhkWr7kVVPV5Vvx4fPsHo9Qxb0ZCfC4CvAz8EXtvI4TbYkL24HXikql4GqKqtuh9D9qKADycJ8CFGwT+3sWOuv6p6jNH3dj5r6uZ6B/98t1y40DVbwYV+n19l9Df4VrTqXiTZAXwJOLSBc22GIT8XVwGXJ/l5kpNJ7tiw6TbWkL24H/g0oxd2PgN8o6re2ZjxLipr6uaQWytMYmq3ZdgCBn+fST7PKPh/sq4TbZ4he/Ed4J6qent0MbdlDdmL7cD1wBeA3wX+LckTVfXieg+3wYbsxReBJ4E/B/4Q+Ock/1pV/73Os11s1tTN9Q6+t2VYNOj7THIN8BCwv6p+tUGzbbQhezELHB3H/grg5iTnqupHGzLhxhn6Z+T1qnoTeDPJY8C1wFYL/pC9uBP4+xo9kT2f5CXgauDfN2bEi8aaurneT+l4W4ZFq+5FkiuBR4CvbMGrt6VW3Yuq2l1Vn6yqTwL/CPzNFow9DPsz8mPgc0m2J/kgo7vVPr/Bc26EIXvxMqN/6ZDk44zuHHl6Q6e8OKypm+t6hV/rd1uG952Be/FN4KPAg+Mr23O1Be8QOHAvWhiyF1X1fJKfAU8D7wAPVdWWu7X4wJ+L+4CHkzzD6GmNe6pqy902OckPgJuAK5IsAN8CPgCTddNbK0hSE77SVpKaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrifwHXe3WluIZOawAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "obj = 4\n",
    "#print(xtrain)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kde\n",
    "\n",
    "\n",
    "while obj<5:\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax2 = fig.add_subplot(111)\n",
    "    #ytrain.append(ytrain[1,1])\n",
    "    #ytest = np.delete(ytest, 0, axis=0)\n",
    "    #predictions = np.delete(predictions, 2)\n",
    "#     #np.delete(ytest[:,obj], 1)\n",
    "#     print(len(predictions))\n",
    "#     print(len(ytest[:,obj]))\n",
    "#     print(len(ytrain[:,obj]))\n",
    "\n",
    "\n",
    "    \n",
    "    heatplots=True\n",
    "    if heatplots:\n",
    "        nbins=300\n",
    "        k = kde.gaussian_kde( [  ytest[:,obj], predictions  ])\n",
    "        xi, yi = np.mgrid[ytest[:,obj].min():ytest[:,obj].max():nbins*1j, predictions.min():predictions.max():nbins*1j]\n",
    "        zi = k(np.vstack([xi.flatten(), yi.flatten()]))\n",
    "\n",
    "        ax2.pcolormesh(xi, yi, zi.reshape(xi.shape))\n",
    "        #plt.show()\n",
    "    \n",
    "        \n",
    "    \n",
    "    ax2.scatter(ytest[:,obj], ytest[:,obj],\n",
    "             \n",
    "             label='y=x',\n",
    "            s=10, c='y', marker=\"s\",\n",
    "             )\n",
    "    ax2.scatter(ytest[:,obj], predictions,\n",
    "             s=.01, c='r', marker=\"o\",\n",
    "             label='Prediction')\n",
    "#     ax2.scatter(ytest[:,obj], ytrain[:,obj], \n",
    "#              s=1, c='g', marker=\"o\",\n",
    "#              label='Prediction')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    ax2.set_aspect(1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if obj==0:\n",
    "        ax2.set_xlabel('transmission(%)')\n",
    "        ax2.set_ylabel('transmission(%)')\n",
    "        ax2.set_aspect(1)\n",
    "        \n",
    "    if obj==1:\n",
    "        ax2.set_xlabel('Energy(MeV)')\n",
    "        ax2.set_ylabel('Energy(MeV)')\n",
    "        ax2.set_aspect(1)\n",
    "        \n",
    "    if obj==2:\n",
    "        ax2.set_xlabel('length(mm)')\n",
    "        ax2.set_ylabel('length(mm)')\n",
    "        ax2.set_aspect(1)\n",
    "    \n",
    "    if obj==3:\n",
    "        ax2.set_xlabel('Longitudinal emit (mm*mrad)')\n",
    "        ax2.set_ylabel('Longitudinal emit (mm*mrad)')\n",
    "        ax2.set_aspect(1)\n",
    "        \n",
    "    \n",
    "    if obj==4:\n",
    "        ax2.set_xlabel('X emit (mm*mrad)')\n",
    "        ax2.set_ylabel('X emit (mm*mrad)')\n",
    "        ax2.set_xlim(.01, .07)\n",
    "        ax2.set_ylim(.01, .07)\n",
    "                \n",
    "    if obj==5:\n",
    "        ax2.set_xlabel('Y emit (mm*mrad)')\n",
    "        ax2.set_ylabel('Y emit (mm*mrad)')\n",
    "        ax2.set_xlim(.01, .07)\n",
    "        ax2.set_ylim(.01, .07)\n",
    "        ax2.set_aspect(1)\n",
    "        \n",
    "\n",
    "    #ax2.set_xlim(0.055, .1)\n",
    "    #ax2.set_ylim(0, .1)\n",
    "    #ax2.set_xlim(0, .1)\n",
    "    plt.legend(loc='upper left');\n",
    "    \n",
    "\n",
    "#plt.plot(xvals[:,1], yvals[:,1], label='')\n",
    "   \n",
    "    plt.show()\n",
    "    #print(\" value:  \",  pow(np.average(predictions[obj]-ytest[:,obj]), 2)      /       pow(np.average(ytrain[:,obj]), 2))\n",
    "    print('L2 error norm in validation points: ', eval_l2_error(ytrue=ytest[:, i], ypred=ypred_test))\n",
    "    obj = obj +1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd \n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mclr\n",
    "\n",
    "\n",
    "voltages=np.array([15,15.5,16,15,15.5,16,15.5,16,15.5,16,16,16,16,17,17.5,18,17.5,18,18])\n",
    "angles=np.array([20,20,20,20.5,20.5,20.5,21,21,21.5,21.5,22,22.5,23,25,25,25,26,26,27])\n",
    "emits=np.array([0.000000135,0.000000136197,0.000000138,0.000000133,0.000000135,0.000000136437,0.000000133,0.000000135,0.000000132,0.000000133,0.000000132,0.000000131,0.00000013,0.000000127,0.000000128,0.000000129,0.000000125,0.000000126,0.00000012386])\n",
    "\n",
    "angle,voltages = np.meshgrid(angles, voltages, indexing='ij')\n",
    "  \n",
    "#voltages, angles = np.meshgrid(voltages, angles) \n",
    "  \n",
    "# surface plot for a + b \n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.pcolormesh(angles, voltages, emits, edgecolors='w',cmap=\"plasma\")\n",
    "  \n",
    "plt.show() \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rho histogram\n",
    "#fig, ax = plt.subplots()\n",
    "#\n",
    "#plt.sca(ax[0, 2])\n",
    "\n",
    "\n",
    "voltages=np.array([15,15.5,16,15,15.5,16,15.5,16,15.5,16,16,16,16,17,17.5,18,17.5,18,18])\n",
    "angles=np.array([20,20,20,20.5,20.5,20.5,21,21,21.5,21.5,22,22.5,23,25,25,25,26,26,27])\n",
    "emits=np.array([0.000000135,0.000000136197,0.000000138,0.000000133,0.000000135,0.000000136437,0.000000133,0.000000135,0.000000132,0.000000133,0.000000132,0.000000131,0.00000013,0.000000127,0.000000128,0.000000129,0.000000125,0.000000126,0.00000012386])\n",
    "#emits= normalize(emits)\n",
    "\n",
    "plt.hist2d(angles, voltages,  bins=[10, 10],range=[[19, 28], [13, 20]],\n",
    "           weights=emits, cmap=plt.cm.rainbow)\n",
    "plt.clim(.00000012, .00000014)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.xlabel(\"angles\")\n",
    "plt.ylabel(\"voltages\")\n",
    "plt.title(\"Charge Density (C/m^3)\")\n",
    "plt.gca().set_aspect(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <div class=\"alert alert-info\" role=\"alert\" style=\"margin-top: 10px; font-size: 30px;\">\n",
    "        <strong>Plot Main and Total Sensitivities</strong>\n",
    "    </div>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "\n",
    "import itertools as it\n",
    "import subprocess\n",
    "from scipy import optimize as opt\n",
    "import numpy as npr\n",
    "from time import time, ctime\n",
    "from datetime import date\n",
    "from datetime import datetime as dt\n",
    "import wave\n",
    "import random\n",
    "from bayes_opt import BayesianOptimization\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from db import mldb\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#from mllib.model import *\n",
    "#from mllib.data import OpalDataSource\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "def opt_fun (lmax, n, a, learn_rate):\n",
    "\n",
    "    # list of hyperparams: number of layers(lmax), number of nodes per layer(n[l]), activation function(a[l], =0,1,2) \n",
    "    # learning rate\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(14, input_dim=14, activation='sigmoid'))\n",
    "    \n",
    "    l=0\n",
    "    while l<lmax:\n",
    "        if a[l]==0:\n",
    "            model.add(Dense(n[l], activation='relu'))\n",
    "    \n",
    "        if a[l]==1:\n",
    "            model.add(Dense(n[l], activation='tanh'))\n",
    "        if a[l]==2:\n",
    "            model.add(Dense(n[l], activation='sigmoid'))\n",
    "        l=l+1\n",
    "    \n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    #model.add(Dense(6))\n",
    "    #model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "    model.compile(\n",
    "        loss=keras.losses.MeanSquaredError(),\n",
    "        #use loss squared function\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learn_rate),\n",
    "        #switch to adam\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "        )\n",
    "    \n",
    "    \n",
    "    \n",
    "    obj=5\n",
    "    models=[]\n",
    "    norms=[]\n",
    "    epochs=1000\n",
    "    batch_size=1024\n",
    "\n",
    "    print(len(ytrain[:,obj]))\n",
    "    print(len(ytrain[obj,:]))\n",
    "    while obj<6:\n",
    "    \n",
    "        normfactor=np.max(ytrain[:,obj])*1.1\n",
    "        print(normfactor)\n",
    "        #normfactor=normalize(ytrain[:,obj])\n",
    "        #trainer=normalize(ytrain[:,obj])\n",
    "        norms.append(normfactor)\n",
    "        model.fit(xtrain, ytrain[:,obj]/normfactor, batch_size=batch_size, epochs=epochs, validation_split=0.0)\n",
    "        # Test the model\n",
    "        #model.evaluate(xtest, ytest[:,obj])\n",
    "        models.append(model)\n",
    "        obj=obj+1\n",
    "        #shuffle_weights(model, weights=None)\n",
    "    \n",
    "    obj=5\n",
    "    \n",
    "    \n",
    "    \n",
    "    utility=99999999999999999999999\n",
    "    print(\"MAE: \", np.average(abs(models[0].predict(xtest)*norms[0]-ytest[:,5])))\n",
    "    utility= -1*np.average(abs(models[0].predict(xtest)*norms[0]-ytest[:,5]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"utility: \", utility)\n",
    "    return utility\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print( opt_fun(10,[100,80,50,50, 20,20,20,20,20,20], [1,1,2,1,1,1,1,1,1,2],0.0005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_fun2 (nodes, learn_rate):\n",
    "    print(\"nodes: \", round(nodes), \"      learn_rate:\", learn_rate)\n",
    "    global iteration \n",
    "    iteration = iteration+1\n",
    "    print(\"iteration:  \", iteration)\n",
    "    \n",
    "    return opt_fun(5,[15,20,20,20, round(nodes)], [1,1,1,1,1], learn_rate)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(opt_fun(x0))\n",
    "#res = minimize(opt_fun, x0, method='nelder-mead',\n",
    "#               options={'xatol': 1e-5, 'disp': True})\n",
    "#res = minimize_scalar(opt_fun, bounds=    )\n",
    "\n",
    "field_scale = 1 # Adjustments to field strength weight for optimization\n",
    "# Params for optimizer\n",
    "n_iter = 400\n",
    "init_points = 20\n",
    "\n",
    "\n",
    "printout= \"words\"\n",
    "\n",
    "\n",
    "def main():\n",
    "    global printout\n",
    "    #numProc = mp.cpu_count() # Number of Processes to spawn\n",
    "    #x0 = np.asarray([000.0, 00.0, 000.0])\n",
    "    #dimension=14\n",
    "    start = time()\n",
    "\n",
    "    print('Optimizing using BO, PP')\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    #lmax=5\n",
    "    \n",
    "    # 18 parameter bounds Format: 'name': (min, max), \n",
    "    bnds = {\n",
    "        'nodes': (1, 80),\n",
    "        'learn_rate': (0, .01)\n",
    "        } \n",
    "\n",
    "    \n",
    "    \n",
    "    # Optimization process\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=opt_fun2,\n",
    "        pbounds=bnds,\n",
    "        verbose=0,\n",
    "        random_state=1,\n",
    "    )\n",
    "\n",
    "    optimizer.maximize(\n",
    "        init_points=init_points,\n",
    "        n_iter=n_iter,\n",
    "    )\n",
    "    results = optimizer.max\n",
    "\n",
    "\n",
    "    print('-------------------------------------------------')\n",
    "    print( 'OPTIMIZATION ENDED' )\n",
    "    print( \"utility:\", -1*results['target'])\n",
    "    print (\"params: \", results['params'])\n",
    "    \n",
    "    printout= 'printout: '\n",
    "    printout.append(\"utility: \", -1*results['target'], \"           params:\", results['params'])\n",
    "\n",
    "    end = time()\n",
    "    print(\"Elapsed time: \", end - start, \" seconds\")\n",
    "    \n",
    "\n",
    "\n",
    "    print(\"optimization completed:\", dt.now().strftime('%y.%m.%d-%H:%M:%S')        )\n",
    "  \n",
    "  \n",
    "main()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(printout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.legend(loc='upper left');\n",
    "plt.figure(figsize=(12, 9), dpi=150)\n",
    "plt = plot_sensitivity(allsens_m, dnames=xnames, outnames=ynames, sens_type='Main')\n",
    "\n",
    "plt.savefig('main_sensitivty_order_' + str(order) + '.png', bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 9), dpi=150)\n",
    "plt = plot_sensitivity(allsens_t, dnames=xnames, outnames=ynames, sens_type='Total')\n",
    "\n",
    "plt.savefig('total_sensitivty_order_' + str(order) + '.png', bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(len(xvals))\n",
    "print(len(yvals))\n",
    "print(len(ypred_test))\n",
    "print(len(xtest))\n",
    "\n",
    "obj=0\n",
    "\n",
    "\n",
    "while obj<6:\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "\n",
    "    ax1.scatter(xvals[:,obj], yvals[:,obj],\n",
    "             \n",
    "            label='Data',\n",
    "           s=10, c='b', marker=\"s\",\n",
    "            )\n",
    "    ax1.scatter(xtest[:,obj], ypred_test,\n",
    "             s=10, c='r', marker=\"o\",\n",
    "             label='Prediction')\n",
    "\n",
    "    #ax1.set_ylim(0, 1.)\n",
    "    plt.legend(loc='upper left');\n",
    "\n",
    "#plt.plot(xvals[:,1], yvals[:,1], label='')\n",
    "    plt.show()\n",
    "    obj = obj +1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "obj = 0\n",
    "#print(xtrain)\n",
    "\n",
    "\n",
    "while obj<6:\n",
    "    predictions=[]\n",
    "    predictions=models[obj].predict(xtest)*norms[obj]\n",
    "    print(len(predictions))\n",
    "    print(len(ytest))\n",
    "    fig = plt.figure()\n",
    "    ax2 = fig.add_subplot(111)\n",
    "    \n",
    "\n",
    "    ax2.scatter(ytest[:,obj], ytest[:,obj],\n",
    "             \n",
    "             label='y=x',\n",
    "            s=1, c='b', marker=\"s\",\n",
    "             )\n",
    "    ax2.scatter(ytest[:,obj], predictions,\n",
    "             s=1, c='r', marker=\"o\",\n",
    "             label='Prediction')\n",
    "    ax2.set_aspect(1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if obj==0:\n",
    "        ax2.set_xlabel('transmission(%)')\n",
    "        ax2.set_ylabel('transmission(%)')\n",
    "    \n",
    "    if obj==1:\n",
    "        ax2.set_xlabel('Energy(MeV)')\n",
    "        ax2.set_ylabel('Energy(MeV)')\n",
    "        \n",
    "    if obj==2:\n",
    "        ax2.set_xlabel('length(mm)')\n",
    "        ax2.set_ylabel('length(mm)')\n",
    "        \n",
    "    \n",
    "    if obj==3:\n",
    "        ax2.set_xlabel('Longitudinal emit (mm*mrad)')\n",
    "        ax2.set_ylabel('Longitudinal emit (mm*mrad)')\n",
    "        \n",
    "        \n",
    "    \n",
    "    if obj==4:\n",
    "        ax2.set_xlabel('X emit (mm*mrad)')\n",
    "        ax2.set_ylabel('X emit (mm*mrad)')\n",
    "                \n",
    "    if obj==5:\n",
    "        ax2.set_xlabel('Y emit (mm*mrad)')\n",
    "        ax2.set_ylabel('Y emit (mm*mrad)')\n",
    "        \n",
    "\n",
    "    #ax2.set_xlim(0.055, .1)\n",
    "    #ax2.set_ylim(0, .1)\n",
    "    #ax2.set_xlim(0, .1)\n",
    "    plt.legend(loc='upper left');\n",
    "    \n",
    "\n",
    "#plt.plot(xvals[:,1], yvals[:,1], label='')\n",
    "    plt.show()\n",
    "    obj = obj +1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(xtest)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "i=0\n",
    "\n",
    "print(\"output:  \")\n",
    "#print(output)\n",
    "#print(len(output))\n",
    "print(\"   \")\n",
    "print(\"xtest:   \")\n",
    "print(xtest)\n",
    "print(len(xtest[i,:]))\n",
    "print(len(xtest[:,i]))\n",
    "\n",
    "\n",
    "\n",
    "xinput = [[10.01277,\n",
    "102.13058,\n",
    "11.38499,\n",
    "150.15528,\n",
    "149.87416,\n",
    "32.79421,\n",
    "47.35732,\n",
    "91.13554,\n",
    "1.0339,\n",
    "1.18602,\n",
    "1.55939,\n",
    "-85.4561,\n",
    "-65.20657,\n",
    "-56.44278],[0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "         ]\n",
    "\n",
    "\n",
    "outputs =[]\n",
    "\n",
    "\n",
    "# while i<14:\n",
    "    \n",
    "#      print(xtest[0,i]         )\n",
    "#      #outputs.append(output[i])\n",
    "#      #print(output[i])\n",
    "     \n",
    "#      i=i+1\n",
    "\n",
    "p=0\n",
    "while p<6:\n",
    "    outputs.append(surrogates[p].predict(xinput))\n",
    "    print(surrogates[p].predict(xinput))\n",
    "    p=p+1    \n",
    "    print(len(outputs))\n",
    "\n",
    "print(\"\")    \n",
    "print(\"outputs: \")    \n",
    "print(\"\")\n",
    "p=0\n",
    "while p<6:\n",
    "    print(outputs[p][0])\n",
    "    p=p+1        \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "weights =[1,1,1,1,1,1,1]\n",
    "# #utility = \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "while i<6:\n",
    "    plt.hist(ytrain[:,i], bins=20)\n",
    "    \n",
    "    plt.show()\n",
    "    i=i+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "\n",
    "import itertools as it\n",
    "import subprocess\n",
    "from scipy import optimize as opt\n",
    "import numpy as npr\n",
    "from time import time, ctime\n",
    "from datetime import date\n",
    "from datetime import datetime as dt\n",
    "import wave\n",
    "import random\n",
    "import multiprocessing as mp\n",
    "from bayes_opt import BayesianOptimization\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def opt_fun (dvar1,dvar2,dvar3,dvar4,dvar5,dvar6,dvar7,dvar8,dvar9,dvar10,dvar11,dvar12,dvar13,dvar14):\n",
    "    \n",
    "    utility=0\n",
    "#     utility=0\n",
    "#     dvar1=x[0]\n",
    "#     dvar2=x[1]\n",
    "#     dvar3=x[2]\n",
    "#     dvar4=x[3]\n",
    "#     dvar5=x[4]\n",
    "#     dvar6=x[5]\n",
    "#     dvar7=x[6]\n",
    "#     dvar8=x[7]\n",
    "#     dvar9=x[8]\n",
    "#     dvar10=x[9]\n",
    "#     dvar11=x[10]\n",
    "#     dvar12=x[11]\n",
    "#     dvar13=x[12]\n",
    "#     dvar14=x[13]\n",
    "#     obj=x[14]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    xinput = [[dvar1,\n",
    "    dvar2,\n",
    "    dvar3,\n",
    "    dvar4,\n",
    "    dvar5,\n",
    "    dvar6,\n",
    "    dvar7, \n",
    "    dvar8, \n",
    "    dvar9, \n",
    "    dvar10,\n",
    "    dvar11,\n",
    "    dvar12,\n",
    "    dvar13, \n",
    "    dvar14],\n",
    "    [0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "         ]\n",
    "    outputs=[]\n",
    "    outputs.clear()\n",
    "    obj=6\n",
    "    p=0\n",
    "    while p<obj:\n",
    "        outputs.append(surrogates[p].predict(xinput))\n",
    "        p=p+1    \n",
    "    \n",
    "    \n",
    "    optimum = [100, 70, 130, 0, 0, 0]\n",
    "    weights= [ 0.4/50, 0.05/.075, 0.05/140, 0.4/.006, 0.05/.0035, 0.05/.0035]\n",
    "    obj=6\n",
    "    \n",
    "    \n",
    "    i=0\n",
    "    while i<obj:\n",
    "        utility += -((optimum[i]-outputs[i][0])*(optimum[i]-outputs[i][0])*weights[i])\n",
    "        i=i+1\n",
    "        \n",
    "    return utility\n",
    "    \n",
    "    \n",
    "\n",
    "x0 = [10.01277,\n",
    "102.13058,\n",
    "11.38499,\n",
    "150.15528,\n",
    "149.87416,\n",
    "32.79421,\n",
    "47.35732,\n",
    "91.13554,\n",
    "1.0339,\n",
    "1.18602,\n",
    "1.55939,\n",
    "-85.4561,\n",
    "-65.20657,\n",
    "-56.44278,\n",
    "     6]\n",
    "\n",
    "\n",
    "#print(opt_fun(x0))\n",
    "#res = minimize(opt_fun, x0, method='nelder-mead',\n",
    "#               options={'xatol': 1e-5, 'disp': True})\n",
    "#res = minimize_scalar(opt_fun, bounds=    )\n",
    "\n",
    "field_scale = 1 # Adjustments to field strength weight for optimization\n",
    "# Params for optimizer\n",
    "n_iter = 1000\n",
    "init_points = 10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    numProc = mp.cpu_count() # Number of Processes to spawn\n",
    "    x0 = np.asarray([000.0, 00.0, 000.0])\n",
    "    dimension=14\n",
    "    start = time()\n",
    "\n",
    "    print('Optimizing using BO, PP')\n",
    "\n",
    "    #dvar1min, dvar2min, dvar3min, dvar4min, dvar5min, dvar6min, dvar7min, dvar8min, dvar9min, dvar10min, dvar11min, dvar12min,  dvar13min, dvar14min = 30,30,30,30,30,30,30,30,30,30,30,30,30,30\n",
    "    dvar1min, dvar2min, dvar3min, dvar4min, dvar5min, dvar6min, dvar7min, dvar8min, dvar9min, dvar10min, dvar11min, dvar12min,  dvar13min, dvar14min = 10.01277,102.13058,8.38499,120.15528,129.87416,32.79421,47.35732,91.13554,1.0339,1.18602,1.55939,-85.4561,-5.20657,-56.44278\n",
    "    #dvar1max, dvar2max, dvar3max, dvar4max, dvar5max, dvar6max, dvar7max, dvar8max, dvar9max, dvar10max, dvar11max, dvar12max,  dvar13max, dvar14max = 40,40,40,40,40,40,40,40,40,40,40,40,40,40\n",
    "    dvar1max, dvar2max, dvar3max, dvar4max, dvar5max, dvar6max, dvar7max, dvar8max, dvar9max, dvar10max, dvar11max, dvar12max,  dvar13max, dvar14max = 20.01277,112.13058,11.38499,150.15528,150.87416,35.79421,50.35732,96.13554,1.839,2.18602,2.55939,-75.4561,-3.20657,-46.44278\n",
    "\n",
    "    print(opt_fun(dvar1min, dvar2min, dvar3min, dvar4min, dvar5min, dvar6min, dvar7min, dvar8min, dvar9min, dvar10min, dvar11min, dvar12min,  dvar13min, dvar14min))\n",
    "    \n",
    "#     bnds = {\n",
    "#         (dvar1min, dvar1max),\n",
    "#         (dvar2min, dvar2max),\n",
    "#         (dvar3min, dvar3max),\n",
    "        \n",
    "#         (dvar4min, dvar4max),\n",
    "#         (dvar5min, dvar5max),\n",
    "#         (dvar6min, dvar6max),\n",
    "#         (dvar7min, dvar7max),\n",
    "#         (dvar8min, dvar8max),\n",
    "#         (dvar9min, dvar9max),\n",
    "#         (dvar10min, dvar10max),\n",
    "#         (dvar11min, dvar11max),\n",
    "#         (dvar12min, dvar12max),\n",
    "        \n",
    "#         (dvar13min, dvar13max),\n",
    "#         (dvar14min, dvar14max)\n",
    "        \n",
    "#         }\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # 18 parameter bounds Format: 'name': (min, max), \n",
    "    bnds = {\n",
    "        'dvar1': (10, 11),\n",
    "        'dvar2': (1, 200.0),\n",
    "        'dvar3': (1, 200.0),\n",
    "        'dvar4': (1, 200.0),\n",
    "        'dvar5': (1, 200.0),\n",
    "        'dvar6': (13.0, 33.0),\n",
    "        'dvar7': (45, 65.0),\n",
    "        'dvar8': (85, 105.0),\n",
    "        'dvar9': (1.005, 1.05),\n",
    "        'dvar10': (1.15, 1.350),\n",
    "        'dvar11': (1.55, 1.750),\n",
    "        'dvar12': (-89.9, -85.0),\n",
    "        'dvar13': (-77.50, -62.50 ),\n",
    "        'dvar14': (-57.5, -42.5)\n",
    "        } \n",
    "\n",
    "    \n",
    "    \n",
    "    # Optimization process\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=opt_fun,\n",
    "        pbounds=bnds,\n",
    "        verbose=0,\n",
    "        random_state=1,\n",
    "    )\n",
    "\n",
    "    optimizer.maximize(\n",
    "        init_points=init_points,\n",
    "        n_iter=n_iter,\n",
    "    )\n",
    "    results = optimizer.max\n",
    "\n",
    "\n",
    "    print('-------------------------------------------------')\n",
    "    print( 'OPTIMIZATION ENDED' )\n",
    "    print( \"utility:\", -1*results['target'])\n",
    "    print (\"params: \", results['params'])\n",
    "\n",
    "    end = time()\n",
    "    print(\"Elapsed time: \", end - start, \" seconds\")\n",
    "    \n",
    "\n",
    "\n",
    "    print(\"optimization completed:\", dt.now().strftime('%y.%m.%d-%H:%M:%S')        )\n",
    "  \n",
    "  \n",
    "main()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_fun_2 (dvar1,dvar2,dvar3,dvar4,dvar5,dvar6,dvar7,dvar8,dvar9,dvar10,dvar11,dvar12,dvar13,dvar14):\n",
    "  \n",
    "    utility=0\n",
    "#     utility=0\n",
    "#     dvar1=x[0]\n",
    "#     dvar2=x[1]\n",
    "#     dvar3=x[2]\n",
    "#     dvar4=x[3]\n",
    "#     dvar5=x[4]\n",
    "#     dvar6=x[5]\n",
    "#     dvar7=x[6]\n",
    "#     dvar8=x[7]\n",
    "#     dvar9=x[8]\n",
    "#     dvar10=x[9]\n",
    "#     dvar11=x[10]\n",
    "#     dvar12=x[11]\n",
    "#     dvar13=x[12]\n",
    "#     dvar14=x[13]\n",
    "#     obj=x[14]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    xinput = [[dvar1,\n",
    "    dvar2,\n",
    "    dvar3,\n",
    "    dvar4,\n",
    "    dvar5,\n",
    "    dvar6,\n",
    "    dvar7, \n",
    "    dvar8, \n",
    "    dvar9, \n",
    "    dvar10,\n",
    "    dvar11,\n",
    "    dvar12,\n",
    "    dvar13, \n",
    "    dvar14],\n",
    "    [0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "         ]\n",
    "    outputs=[]\n",
    "    outputs.clear()\n",
    "    obj=6\n",
    "    p=0\n",
    "    while p<obj:\n",
    "        outputs.append(surrogates[p].predict(xinput))\n",
    "        p=p+1    \n",
    "    \n",
    "    \n",
    "    optimum = [100, 70, 120, 0, 0, 0]\n",
    "    weights= [ 0.4/90, 0.05/.075, 0.05/140, 0.4/.06, 0.05/.035, 0.05/.035]\n",
    "    obj=6\n",
    "    \n",
    "    \n",
    "    i=0\n",
    "    while i<obj:\n",
    "        utility += -((optimum[i]-outputs[i][0])*(optimum[i]-outputs[i][0])*weights[i])\n",
    "        print(outputs[i][0])\n",
    "        i=i+1\n",
    "        \n",
    "    \n",
    "    return utility\n",
    "\n",
    "\n",
    "#opt_fun_2(10.32654950508622,114.09776918706348,95.03503058186705,  4.9373454675155966, 166.65840782020405,  14.51445462045868, 60.39738085611873, 97.90828399113782,  1.0350016324169173,  1.2932711161614976,  1.6896462159652843,  -88.86681948986129, -76.97132158039432, -47.91867664340158)\n",
    "#opt_fun_2(10.0,141.20474878480792, 131.412409553512,  4.572527379802288,  35.30223532987305,  33.0,  55.496663301669955,  85.0, 1.05, 1.15,  1.75,  -89.9,  -77.5,  -57.5,)\n",
    "opt_fun_2( 10.0, 141.20474878480792, 131.412409553512, 4.572527379802288, 35.30223532987305, 33.0, 55.496663301669955, 85.0,  1.05, 1.15,  1.75,  -89.9,  -77.5,  -57.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
